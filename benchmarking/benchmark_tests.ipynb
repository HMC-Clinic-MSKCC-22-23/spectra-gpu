{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Test File\n",
    "\n",
    "Use this notebook to compare a run of SPECTRA with the benchmark data. \n",
    "\n",
    "The data you're comparing is in the folder marked \"benchmark_factors\" on the google drive. There is one csv for each factor, and each file is named the same as the factor you should be comparing it against.\n",
    "\n",
    "There are two main things we're looking at - pairwise correlation between each factor and the intersection of the genes that contribute to each factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import scanpy as sc\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all buggy right now - mainly waiting to see how to match factor weights back to genes, and waiting to see if a new run returns each factor individually like this, or if we have to pull that apart ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing files\n",
    "\n",
    "# new run - remember to change this to be your local file path\n",
    "adata = sc.read_h5ad('C:\\\\Users\\\\phill\\\\Documents\\\\HMCFall22\\\\Clinic\\\\data_for_clinic_2023.h5ad')\n",
    "\n",
    "# grabbing the list of factors from the new data\n",
    "def match(input_string):\n",
    "    return re.findall(r'[\\d]*-X-[\\w_-]*X-norm', input_string)\n",
    "    \n",
    "factor_matches = [match(word) for word in adata.obs]\n",
    "\n",
    "factor_list = []\n",
    "\n",
    "for l in factor_matches:\n",
    "    if l:\n",
    "        factor_list.append(l[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3081531705.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Intersection between factors\n",
    "# for now assuming the anndata looks identical to the benchmark set we recieved.\n",
    "\n",
    "for l in factor_list:\n",
    "    benchmark_factor = []\n",
    "    \n",
    "    # grab the benchmark data\n",
    "    with open('{l}.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "\n",
    "        # get list of factors from csv\n",
    "        factors_1 = list(csv_reader)\n",
    "\n",
    "        csv_file.close()\n",
    "\n",
    "    print(benchmark_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise correlation - buggy\n",
    "corr_mat = np.corrcoef(num_factors_1, num_factors_2)\n",
    "\n",
    "seaborn.clustermap(corr_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d7418673a0aacf14a3144fff84695a701d8309c23224c786571908f2c59a39f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
